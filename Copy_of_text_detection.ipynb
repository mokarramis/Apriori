{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of text-detection.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "GGRWu6cUQp0n",
        "EW9ZN8qaQwj4",
        "nx1GKVanQ_oq",
        "AiqTIVyeTbpV",
        "UI2Ht2Y2Tohs"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mokarramis/Apriori/blob/main/Copy_of_text_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PzQ6LbrV2SA",
        "outputId": "625b6e93-1323-4048-c9a8-9cb7e6331edf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import auth, drive\n",
        "auth.authenticate_user()\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "COLAB_ROOT='/content/gdrive/My Drive/Colab Notebooks/'\n",
        "DESSERT_ROOT = COLAB_ROOT + 'Dessert/'\n",
        "DATA_ROOT = DESSERT_ROOT + 'data/'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_nHjtCjGNWY",
        "outputId": "6b58527b-38aa-40c4-eddd-a130b0e4aff2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install torch torchvision opencv-python"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: pip in /usr/local/lib/python3.6/dist-packages (19.3.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.3.0+cu100)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.4.1+cu100)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (3.4.7.28)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.17.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.3.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7n8_7_ZaQ6ol"
      },
      "source": [
        "from collections import namedtuple, OrderedDict\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "from torch.autograd import Variable\n",
        "from torchvision import models\n",
        "from torchvision.models.vgg import model_urls\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import math\n",
        "import os\n",
        "import time\n",
        "\n",
        "from skimage import io"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGRWu6cUQp0n"
      },
      "source": [
        "## VGG16_bn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1-53oIdJxN9"
      },
      "source": [
        "def init_weights(modules):\n",
        "    for m in modules:\n",
        "        if isinstance(m, nn.Conv2d):\n",
        "            init.xavier_uniform_(m.weight.data)\n",
        "            if m.bias is not None:\n",
        "                m.bias.data.zero_()\n",
        "        elif isinstance(m, nn.BatchNorm2d):\n",
        "            m.weight.data.fill_(1)\n",
        "            m.bias.data.zero_()\n",
        "        elif isinstance(m, nn.Linear):\n",
        "            m.weight.data.normal_(0, 0.01)\n",
        "            m.bias.data.zero_()\n",
        "\n",
        "class vgg16_bn(torch.nn.Module):\n",
        "    def __init__(self, pretrained=True, freeze=True):\n",
        "        super(vgg16_bn, self).__init__()\n",
        "        model_urls['vgg16_bn'] = model_urls['vgg16_bn'].replace('https://', 'http://')\n",
        "        vgg_pretrained_features = models.vgg16_bn(pretrained=pretrained).features\n",
        "        self.slice1 = torch.nn.Sequential()\n",
        "        self.slice2 = torch.nn.Sequential()\n",
        "        self.slice3 = torch.nn.Sequential()\n",
        "        self.slice4 = torch.nn.Sequential()\n",
        "        self.slice5 = torch.nn.Sequential()\n",
        "        for x in range(12):         # conv2_2\n",
        "            self.slice1.add_module(str(x), vgg_pretrained_features[x])\n",
        "        for x in range(12, 19):         # conv3_3\n",
        "            self.slice2.add_module(str(x), vgg_pretrained_features[x])\n",
        "        for x in range(19, 29):         # conv4_3\n",
        "            self.slice3.add_module(str(x), vgg_pretrained_features[x])\n",
        "        for x in range(29, 39):         # conv5_3\n",
        "            self.slice4.add_module(str(x), vgg_pretrained_features[x])\n",
        "\n",
        "        # fc6, fc7 without atrous conv\n",
        "        self.slice5 = torch.nn.Sequential(\n",
        "                nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
        "                nn.Conv2d(512, 1024, kernel_size=3, padding=6, dilation=6),\n",
        "                nn.Conv2d(1024, 1024, kernel_size=1)\n",
        "        )\n",
        "\n",
        "        if not pretrained:\n",
        "            init_weights(self.slice1.modules())\n",
        "            init_weights(self.slice2.modules())\n",
        "            init_weights(self.slice3.modules())\n",
        "            init_weights(self.slice4.modules())\n",
        "\n",
        "        init_weights(self.slice5.modules())        # no pretrained model for fc6 and fc7\n",
        "\n",
        "        if freeze:\n",
        "            for param in self.slice1.parameters():      # only first conv\n",
        "                param.requires_grad= False\n",
        "\n",
        "    def forward(self, X):\n",
        "        h = self.slice1(X)\n",
        "        h_relu2_2 = h\n",
        "        h = self.slice2(h)\n",
        "        h_relu3_2 = h\n",
        "        h = self.slice3(h)\n",
        "        h_relu4_3 = h\n",
        "        h = self.slice4(h)\n",
        "        h_relu5_3 = h\n",
        "        h = self.slice5(h)\n",
        "        h_fc7 = h\n",
        "        vgg_outputs = namedtuple(\"VggOutputs\", ['fc7', 'relu5_3', 'relu4_3', 'relu3_2', 'relu2_2'])\n",
        "        out = vgg_outputs(h_fc7, h_relu5_3, h_relu4_3, h_relu3_2, h_relu2_2)\n",
        "        return out\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EW9ZN8qaQwj4"
      },
      "source": [
        "## craft"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiX_a3nBQtsN"
      },
      "source": [
        "\n",
        "class double_conv(nn.Module):\n",
        "    def __init__(self, in_ch, mid_ch, out_ch):\n",
        "        super(double_conv, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_ch + mid_ch, mid_ch, kernel_size=1),\n",
        "            nn.BatchNorm2d(mid_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(mid_ch, out_ch, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class CRAFT(nn.Module):\n",
        "    def __init__(self, pretrained=False, freeze=False):\n",
        "        super(CRAFT, self).__init__()\n",
        "\n",
        "        \"\"\" Base network \"\"\"\n",
        "        self.basenet = vgg16_bn(pretrained, freeze)\n",
        "\n",
        "        \"\"\" U network \"\"\"\n",
        "        self.upconv1 = double_conv(1024, 512, 256)\n",
        "        self.upconv2 = double_conv(512, 256, 128)\n",
        "        self.upconv3 = double_conv(256, 128, 64)\n",
        "        self.upconv4 = double_conv(128, 64, 32)\n",
        "\n",
        "        num_class = 2\n",
        "        self.conv_cls = nn.Sequential(\n",
        "            nn.Conv2d(32, 32, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, 32, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, 16, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(16, 16, kernel_size=1), nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(16, num_class, kernel_size=1),\n",
        "        )\n",
        "\n",
        "        init_weights(self.upconv1.modules())\n",
        "        init_weights(self.upconv2.modules())\n",
        "        init_weights(self.upconv3.modules())\n",
        "        init_weights(self.upconv4.modules())\n",
        "        init_weights(self.conv_cls.modules())\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \"\"\" Base network \"\"\"\n",
        "        sources = self.basenet(x)\n",
        "\n",
        "        \"\"\" U network \"\"\"\n",
        "        y = torch.cat([sources[0], sources[1]], dim=1)\n",
        "        y = self.upconv1(y)\n",
        "\n",
        "        y = F.interpolate(y, size=sources[2].size()[2:], mode='bilinear', align_corners=False)\n",
        "        y = torch.cat([y, sources[2]], dim=1)\n",
        "        y = self.upconv2(y)\n",
        "\n",
        "        y = F.interpolate(y, size=sources[3].size()[2:], mode='bilinear', align_corners=False)\n",
        "        y = torch.cat([y, sources[3]], dim=1)\n",
        "        y = self.upconv3(y)\n",
        "\n",
        "        y = F.interpolate(y, size=sources[4].size()[2:], mode='bilinear', align_corners=False)\n",
        "        y = torch.cat([y, sources[4]], dim=1)\n",
        "        feature = self.upconv4(y)\n",
        "\n",
        "        y = self.conv_cls(feature)\n",
        "\n",
        "        return y.permute(0,2,3,1), feature"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nx1GKVanQ_oq"
      },
      "source": [
        "## craft_utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUd1b3wITbC3"
      },
      "source": [
        "\n",
        "\"\"\" auxilary functions \"\"\"\n",
        "# unwarp corodinates\n",
        "def warpCoord(Minv, pt):\n",
        "    out = np.matmul(Minv, (pt[0], pt[1], 1))\n",
        "    return np.array([out[0]/out[2], out[1]/out[2]])\n",
        "\"\"\" end of auxilary functions \"\"\"\n",
        "\n",
        "\n",
        "def getDetBoxes_core(textmap, linkmap, text_threshold, link_threshold, low_text):\n",
        "    # prepare data\n",
        "    linkmap = linkmap.copy()\n",
        "    textmap = textmap.copy()\n",
        "    img_h, img_w = textmap.shape\n",
        "\n",
        "    \"\"\" labeling method \"\"\"\n",
        "    ret, text_score = cv2.threshold(textmap, low_text, 1, 0)\n",
        "    ret, link_score = cv2.threshold(linkmap, link_threshold, 1, 0)\n",
        "\n",
        "    text_score_comb = np.clip(text_score + link_score, 0, 1)\n",
        "    nLabels, labels, stats, centroids = cv2.connectedComponentsWithStats(text_score_comb.astype(np.uint8), connectivity=4)\n",
        "\n",
        "    det = []\n",
        "    mapper = []\n",
        "    for k in range(1,nLabels):\n",
        "        # size filtering\n",
        "        size = stats[k, cv2.CC_STAT_AREA]\n",
        "        if size < 10: continue\n",
        "\n",
        "        # thresholding\n",
        "        if np.max(textmap[labels==k]) < text_threshold: continue\n",
        "\n",
        "        # make segmentation map\n",
        "        segmap = np.zeros(textmap.shape, dtype=np.uint8)\n",
        "        segmap[labels==k] = 255\n",
        "        segmap[np.logical_and(link_score==1, text_score==0)] = 0   # remove link area\n",
        "        x, y = stats[k, cv2.CC_STAT_LEFT], stats[k, cv2.CC_STAT_TOP]\n",
        "        w, h = stats[k, cv2.CC_STAT_WIDTH], stats[k, cv2.CC_STAT_HEIGHT]\n",
        "        niter = int(math.sqrt(size * min(w, h) / (w * h)) * 2)\n",
        "        sx, ex, sy, ey = x - niter, x + w + niter + 1, y - niter, y + h + niter + 1\n",
        "        # boundary check\n",
        "        if sx < 0 : sx = 0\n",
        "        if sy < 0 : sy = 0\n",
        "        if ex >= img_w: ex = img_w\n",
        "        if ey >= img_h: ey = img_h\n",
        "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(1 + niter, 1 + niter))\n",
        "        segmap[sy:ey, sx:ex] = cv2.dilate(segmap[sy:ey, sx:ex], kernel)\n",
        "\n",
        "        # make box\n",
        "        np_contours = np.roll(np.array(np.where(segmap!=0)),1,axis=0).transpose().reshape(-1,2)\n",
        "        rectangle = cv2.minAreaRect(np_contours)\n",
        "        box = cv2.boxPoints(rectangle)\n",
        "\n",
        "        # align diamond-shape\n",
        "        w, h = np.linalg.norm(box[0] - box[1]), np.linalg.norm(box[1] - box[2])\n",
        "        box_ratio = max(w, h) / (min(w, h) + 1e-5)\n",
        "        if abs(1 - box_ratio) <= 0.1:\n",
        "            l, r = min(np_contours[:,0]), max(np_contours[:,0])\n",
        "            t, b = min(np_contours[:,1]), max(np_contours[:,1])\n",
        "            box = np.array([[l, t], [r, t], [r, b], [l, b]], dtype=np.float32)\n",
        "\n",
        "        # make clock-wise order\n",
        "        startidx = box.sum(axis=1).argmin()\n",
        "        box = np.roll(box, 4-startidx, 0)\n",
        "        box = np.array(box)\n",
        "\n",
        "        det.append(box)\n",
        "        mapper.append(k)\n",
        "\n",
        "    return det, labels, mapper\n",
        "\n",
        "def getPoly_core(boxes, labels, mapper, linkmap):\n",
        "    # configs\n",
        "    num_cp = 5\n",
        "    max_len_ratio = 0.7\n",
        "    expand_ratio = 1.45\n",
        "    max_r = 2.0\n",
        "    step_r = 0.2\n",
        "\n",
        "    polys = []  \n",
        "    for k, box in enumerate(boxes):\n",
        "        # size filter for small instance\n",
        "        w, h = int(np.linalg.norm(box[0] - box[1]) + 1), int(np.linalg.norm(box[1] - box[2]) + 1)\n",
        "        if w < 10 or h < 10:\n",
        "            polys.append(None); continue\n",
        "\n",
        "        # warp image\n",
        "        tar = np.float32([[0,0],[w,0],[w,h],[0,h]])\n",
        "        M = cv2.getPerspectiveTransform(box, tar)\n",
        "        word_label = cv2.warpPerspective(labels, M, (w, h), flags=cv2.INTER_NEAREST)\n",
        "        try:\n",
        "            Minv = np.linalg.inv(M)\n",
        "        except:\n",
        "            polys.append(None); continue\n",
        "\n",
        "        # binarization for selected label\n",
        "        cur_label = mapper[k]\n",
        "        word_label[word_label != cur_label] = 0\n",
        "        word_label[word_label > 0] = 1\n",
        "\n",
        "        \"\"\" Polygon generation \"\"\"\n",
        "        # find top/bottom contours\n",
        "        cp = []\n",
        "        max_len = -1\n",
        "        for i in range(w):\n",
        "            region = np.where(word_label[:,i] != 0)[0]\n",
        "            if len(region) < 2 : continue\n",
        "            cp.append((i, region[0], region[-1]))\n",
        "            length = region[-1] - region[0] + 1\n",
        "            if length > max_len: max_len = length\n",
        "\n",
        "        # pass if max_len is similar to h\n",
        "        if h * max_len_ratio < max_len:\n",
        "            polys.append(None); continue\n",
        "\n",
        "        # get pivot points with fixed length\n",
        "        tot_seg = num_cp * 2 + 1\n",
        "        seg_w = w / tot_seg     # segment width\n",
        "        pp = [None] * num_cp    # init pivot points\n",
        "        cp_section = [[0, 0]] * tot_seg\n",
        "        seg_height = [0] * num_cp\n",
        "        seg_num = 0\n",
        "        num_sec = 0\n",
        "        prev_h = -1\n",
        "        for i in range(0,len(cp)):\n",
        "            (x, sy, ey) = cp[i]\n",
        "            if (seg_num + 1) * seg_w <= x and seg_num <= tot_seg:\n",
        "                # average previous segment\n",
        "                if num_sec == 0: break\n",
        "                cp_section[seg_num] = [cp_section[seg_num][0] / num_sec, cp_section[seg_num][1] / num_sec]\n",
        "                num_sec = 0\n",
        "\n",
        "                # reset variables\n",
        "                seg_num += 1\n",
        "                prev_h = -1\n",
        "\n",
        "            # accumulate center points\n",
        "            cy = (sy + ey) * 0.5\n",
        "            cur_h = ey - sy + 1\n",
        "            cp_section[seg_num] = [cp_section[seg_num][0] + x, cp_section[seg_num][1] + cy]\n",
        "            num_sec += 1\n",
        "\n",
        "            if seg_num % 2 == 0: continue # No polygon area\n",
        "\n",
        "            if prev_h < cur_h:\n",
        "                pp[int((seg_num - 1)/2)] = (x, cy)\n",
        "                seg_height[int((seg_num - 1)/2)] = cur_h\n",
        "                prev_h = cur_h\n",
        "\n",
        "        # processing last segment\n",
        "        if num_sec != 0:\n",
        "            cp_section[-1] = [cp_section[-1][0] / num_sec, cp_section[-1][1] / num_sec]\n",
        "\n",
        "        # pass if num of pivots is not sufficient or segment widh is smaller than character height \n",
        "        if None in pp or seg_w < np.max(seg_height) * 0.25:\n",
        "            polys.append(None); continue\n",
        "\n",
        "        # calc median maximum of pivot points\n",
        "        half_char_h = np.median(seg_height) * expand_ratio / 2\n",
        "\n",
        "        # calc gradiant and apply to make horizontal pivots\n",
        "        new_pp = []\n",
        "        for i, (x, cy) in enumerate(pp):\n",
        "            dx = cp_section[i * 2 + 2][0] - cp_section[i * 2][0]\n",
        "            dy = cp_section[i * 2 + 2][1] - cp_section[i * 2][1]\n",
        "            if dx == 0:     # gradient if zero\n",
        "                new_pp.append([x, cy - half_char_h, x, cy + half_char_h])\n",
        "                continue\n",
        "            rad = - math.atan2(dy, dx)\n",
        "            c, s = half_char_h * math.cos(rad), half_char_h * math.sin(rad)\n",
        "            new_pp.append([x - s, cy - c, x + s, cy + c])\n",
        "\n",
        "        # get edge points to cover character heatmaps\n",
        "        isSppFound, isEppFound = False, False\n",
        "        grad_s = (pp[1][1] - pp[0][1]) / (pp[1][0] - pp[0][0]) + (pp[2][1] - pp[1][1]) / (pp[2][0] - pp[1][0])\n",
        "        grad_e = (pp[-2][1] - pp[-1][1]) / (pp[-2][0] - pp[-1][0]) + (pp[-3][1] - pp[-2][1]) / (pp[-3][0] - pp[-2][0])\n",
        "        for r in np.arange(0.5, max_r, step_r):\n",
        "            dx = 2 * half_char_h * r\n",
        "            if not isSppFound:\n",
        "                line_img = np.zeros(word_label.shape, dtype=np.uint8)\n",
        "                dy = grad_s * dx\n",
        "                p = np.array(new_pp[0]) - np.array([dx, dy, dx, dy])\n",
        "                cv2.line(line_img, (int(p[0]), int(p[1])), (int(p[2]), int(p[3])), 1, thickness=1)\n",
        "                if np.sum(np.logical_and(word_label, line_img)) == 0 or r + 2 * step_r >= max_r:\n",
        "                    spp = p\n",
        "                    isSppFound = True\n",
        "            if not isEppFound:\n",
        "                line_img = np.zeros(word_label.shape, dtype=np.uint8)\n",
        "                dy = grad_e * dx\n",
        "                p = np.array(new_pp[-1]) + np.array([dx, dy, dx, dy])\n",
        "                cv2.line(line_img, (int(p[0]), int(p[1])), (int(p[2]), int(p[3])), 1, thickness=1)\n",
        "                if np.sum(np.logical_and(word_label, line_img)) == 0 or r + 2 * step_r >= max_r:\n",
        "                    epp = p\n",
        "                    isEppFound = True\n",
        "            if isSppFound and isEppFound:\n",
        "                break\n",
        "\n",
        "        # pass if boundary of polygon is not found\n",
        "        if not (isSppFound and isEppFound):\n",
        "            polys.append(None); continue\n",
        "\n",
        "        # make final polygon\n",
        "        poly = []\n",
        "        poly.append(warpCoord(Minv, (spp[0], spp[1])))\n",
        "        for p in new_pp:\n",
        "            poly.append(warpCoord(Minv, (p[0], p[1])))\n",
        "        poly.append(warpCoord(Minv, (epp[0], epp[1])))\n",
        "        poly.append(warpCoord(Minv, (epp[2], epp[3])))\n",
        "        for p in reversed(new_pp):\n",
        "            poly.append(warpCoord(Minv, (p[2], p[3])))\n",
        "        poly.append(warpCoord(Minv, (spp[2], spp[3])))\n",
        "\n",
        "        # add to final result\n",
        "        polys.append(np.array(poly))\n",
        "\n",
        "    return polys\n",
        "\n",
        "def getDetBoxes(textmap, linkmap, text_threshold, link_threshold, low_text, poly=False):\n",
        "    boxes, labels, mapper = getDetBoxes_core(textmap, linkmap, text_threshold, link_threshold, low_text)\n",
        "\n",
        "    if poly:\n",
        "        polys = getPoly_core(boxes, labels, mapper, linkmap)\n",
        "    else:\n",
        "        polys = [None] * len(boxes)\n",
        "\n",
        "    return boxes, polys\n",
        "\n",
        "def adjustResultCoordinates(polys, ratio_w, ratio_h, ratio_net = 2):\n",
        "    if len(polys) > 0:\n",
        "        polys = np.array(polys)\n",
        "        for k in range(len(polys)):\n",
        "            if polys[k] is not None:\n",
        "                polys[k] *= (ratio_w * ratio_net, ratio_h * ratio_net)\n",
        "    return polys"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiqTIVyeTbpV"
      },
      "source": [
        "## img_proc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m993T69-Tkhb"
      },
      "source": [
        "\n",
        "def loadImage(img_file):\n",
        "    img = io.imread(img_file)           # RGB order\n",
        "    if img.shape[0] == 2: img = img[0]\n",
        "    if len(img.shape) == 2 : img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
        "    if img.shape[2] == 4:   img = img[:,:,:3]\n",
        "    img = np.array(img)\n",
        "\n",
        "    return img\n",
        "\n",
        "def normalizeMeanVariance(in_img, mean=(0.485, 0.456, 0.406), variance=(0.229, 0.224, 0.225)):\n",
        "    # should be RGB order\n",
        "    img = in_img.copy().astype(np.float32)\n",
        "\n",
        "    img -= np.array([mean[0] * 255.0, mean[1] * 255.0, mean[2] * 255.0], dtype=np.float32)\n",
        "    img /= np.array([variance[0] * 255.0, variance[1] * 255.0, variance[2] * 255.0], dtype=np.float32)\n",
        "    return img\n",
        "\n",
        "def denormalizeMeanVariance(in_img, mean=(0.485, 0.456, 0.406), variance=(0.229, 0.224, 0.225)):\n",
        "    # should be RGB order\n",
        "    img = in_img.copy()\n",
        "    img *= variance\n",
        "    img += mean\n",
        "    img *= 255.0\n",
        "    img = np.clip(img, 0, 255).astype(np.uint8)\n",
        "    return img\n",
        "\n",
        "def resize_aspect_ratio(img, square_size, interpolation, mag_ratio=1):\n",
        "    height, width, channel = img.shape\n",
        "\n",
        "    # magnify image size\n",
        "    target_size = mag_ratio * max(height, width)\n",
        "\n",
        "    # set original image size\n",
        "    if target_size > square_size:\n",
        "        target_size = square_size\n",
        "    \n",
        "    ratio = target_size / max(height, width)    \n",
        "\n",
        "    target_h, target_w = int(height * ratio), int(width * ratio)\n",
        "    proc = cv2.resize(img, (target_w, target_h), interpolation = interpolation)\n",
        "\n",
        "\n",
        "    # make canvas and paste image\n",
        "    target_h32, target_w32 = target_h, target_w\n",
        "    if target_h % 32 != 0:\n",
        "        target_h32 = target_h + (32 - target_h % 32)\n",
        "    if target_w % 32 != 0:\n",
        "        target_w32 = target_w + (32 - target_w % 32)\n",
        "    resized = np.zeros((target_h32, target_w32, channel), dtype=np.float32)\n",
        "    resized[0:target_h, 0:target_w, :] = proc\n",
        "    target_h, target_w = target_h32, target_w32\n",
        "\n",
        "    size_heatmap = (int(target_w/2), int(target_h/2))\n",
        "\n",
        "    return resized, ratio, size_heatmap\n",
        "\n",
        "def cvt2HeatmapImg(img):\n",
        "    img = (np.clip(img, 0, 1) * 255).astype(np.uint8)\n",
        "    img = cv2.applyColorMap(img, cv2.COLORMAP_JET)\n",
        "    return img\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UI2Ht2Y2Tohs"
      },
      "source": [
        "## file_utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7P_EzBnwTk66"
      },
      "source": [
        "\n",
        "# borrowed from https://github.com/lengstrom/fast-style-transfer/blob/master/src/utils.py\n",
        "def get_files(img_dir):\n",
        "    imgs, masks, xmls = list_files(img_dir)\n",
        "    return imgs, masks, xmls\n",
        "\n",
        "def list_files(in_path):\n",
        "    img_files = []\n",
        "    mask_files = []\n",
        "    gt_files = []\n",
        "    for (dirpath, dirnames, filenames) in os.walk(in_path):\n",
        "        for file in filenames:\n",
        "            filename, ext = os.path.splitext(file)\n",
        "            ext = str.lower(ext)\n",
        "            if ext == '.jpg' or ext == '.jpeg' or ext == '.gif' or ext == '.png' or ext == '.pgm':\n",
        "                img_files.append(os.path.join(dirpath, file))\n",
        "            elif ext == '.bmp':\n",
        "                mask_files.append(os.path.join(dirpath, file))\n",
        "            elif ext == '.xml' or ext == '.gt' or ext == '.txt':\n",
        "                gt_files.append(os.path.join(dirpath, file))\n",
        "            elif ext == '.zip':\n",
        "                continue\n",
        "    # img_files.sort()\n",
        "    # mask_files.sort()\n",
        "    # gt_files.sort()\n",
        "    return img_files, mask_files, gt_files\n",
        "\n",
        "def saveResult(img_file, img, boxes, dirname='./result/', verticals=None, texts=None):\n",
        "        \"\"\" save text detection result one by one\n",
        "        Args:\n",
        "            img_file (str): image file name\n",
        "            img (array): raw image context\n",
        "            boxes (array): array of result file\n",
        "                Shape: [num_detections, 4] for BB output / [num_detections, 4] for QUAD output\n",
        "        Return:\n",
        "            None\n",
        "        \"\"\"\n",
        "        img = np.array(img)\n",
        "\n",
        "        # make result file list\n",
        "        filename, file_ext = os.path.splitext(img_file)\n",
        "\n",
        "        # result directory\n",
        "        res_img_file = dirname + filename + '.jpg'\n",
        "\n",
        "        if not os.path.isdir(dirname):\n",
        "            os.mkdir(dirname)\n",
        "\n",
        "        # with open(res_file, 'w') as f:\n",
        "        #     for i, box in enumerate(boxes):\n",
        "        #         poly = np.array(box).astype(np.int32).reshape((-1))\n",
        "        #         strResult = ','.join([str(p) for p in poly]) + '\\r\\n'\n",
        "        #         f.write(strResult)\n",
        "\n",
        "        #         poly = poly.reshape(-1, 2)\n",
        "        #         cv2.polylines(img, [poly.reshape((-1, 1, 2))], True, color=(0, 0, 255), thickness=2)\n",
        "        #         ptColor = (0, 255, 255)\n",
        "        #         if verticals is not None:\n",
        "        #             if verticals[i]:\n",
        "        #                 ptColor = (255, 0, 0)\n",
        "\n",
        "        #         if texts is not None:\n",
        "        #             font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "        #             font_scale = 0.5\n",
        "        #             cv2.putText(img, \"{}\".format(texts[i]), (poly[0][0]+1, poly[0][1]+1), font, font_scale, (0, 0, 0), thickness=1)\n",
        "        #             cv2.putText(img, \"{}\".format(texts[i]), tuple(poly[0]), font, font_scale, (0, 255, 255), thickness=1)\n",
        "\n",
        "        for i, box in enumerate(boxes):\n",
        "            poly = np.array(box).astype(np.int32).reshape((-1))\n",
        "            strResult = ','.join([str(p) for p in poly]) + '\\r\\n'\n",
        "\n",
        "            poly = poly.reshape(-1, 2)\n",
        "            cv2.polylines(img, [poly.reshape((-1, 1, 2))], True, color=(0, 0, 255), thickness=2)\n",
        "            ptColor = (0, 255, 255)\n",
        "            if verticals is not None:\n",
        "                if verticals[i]:\n",
        "                    ptColor = (255, 0, 0)\n",
        "\n",
        "            if texts is not None:\n",
        "                print(texts)\n",
        "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "                font_scale = 0.5\n",
        "                cv2.putText(img, \"{}\".format(texts[i]), (poly[0][0]+1, poly[0][1]+1), font, font_scale, (0, 0, 0), thickness=1)\n",
        "                cv2.putText(img, \"{}\".format(texts[i]), tuple(poly[0]), font, font_scale, (0, 255, 255), thickness=1)\n",
        "        # Save result image\n",
        "        cv2.imwrite(res_img_file, img)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAO1XM6eTn7a"
      },
      "source": [
        "## test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vWBWrN7UMco",
        "outputId": "7a1054fc-5205-4533-c013-4810202d5429",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "class Args:\n",
        "    def __init__(self):\n",
        "        self.trained_model = DESSERT_ROOT + '/weights/craft_mlt_25k.pth'\n",
        "        self.text_threshold=0.7\n",
        "        self.low_text=0.4\n",
        "        self.link_threshold=0.4\n",
        "        self.cuda=True\n",
        "        self.canvas_size=1280\n",
        "        self.mag_ratio=1.5\n",
        "        self.poly=False\n",
        "        self.show_time=False\n",
        "        self.test_folder=DESSERT_ROOT + 'data/test'\n",
        "        self.refine=False\n",
        "        self.refiner_model='weights/craft_refiner_CTW1500.pth'\n",
        "\n",
        "args = Args()\n",
        "\n",
        "def copyStateDict(state_dict):\n",
        "    if list(state_dict.keys())[0].startswith(\"module\"):\n",
        "        start_idx = 1\n",
        "    else:\n",
        "        start_idx = 0\n",
        "    new_state_dict = OrderedDict()\n",
        "    for k, v in state_dict.items():\n",
        "        name = \".\".join(k.split(\".\")[start_idx:])\n",
        "        new_state_dict[name] = v\n",
        "    return new_state_dict\n",
        "\n",
        "def str2bool(v):\n",
        "    return v.lower() in (\"yes\", \"y\", \"true\", \"t\", \"1\")\n",
        "\n",
        "\n",
        "\"\"\" For test images in a folder \"\"\"\n",
        "# image_list, _, _ = get_files(args.test_folder)\n",
        "\n",
        "result_folder = './result/'\n",
        "if not os.path.isdir(result_folder):\n",
        "    os.mkdir(result_folder)\n",
        "\n",
        "def test_net(net, image, text_threshold, link_threshold, low_text, cuda, poly, refine_net=None):\n",
        "    t0 = time.time()\n",
        "\n",
        "    # resize\n",
        "    img_resized, target_ratio, size_heatmap = resize_aspect_ratio(image, args.canvas_size, interpolation=cv2.INTER_LINEAR, mag_ratio=args.mag_ratio)\n",
        "    ratio_h = ratio_w = 1 / target_ratio\n",
        "\n",
        "    # preprocessing\n",
        "    x = normalizeMeanVariance(img_resized)\n",
        "    x = torch.from_numpy(x).permute(2, 0, 1)    # [h, w, c] to [c, h, w]\n",
        "    x = Variable(x.unsqueeze(0))                # [c, h, w] to [b, c, h, w]\n",
        "    if cuda:\n",
        "        x = x.cuda()\n",
        "\n",
        "    # forward pass\n",
        "    y, feature = net(x)\n",
        "\n",
        "    # make score and link map\n",
        "    score_text = y[0,:,:,0].cpu().data.numpy()\n",
        "    score_link = y[0,:,:,1].cpu().data.numpy()\n",
        "\n",
        "    # refine link\n",
        "    if refine_net is not None:\n",
        "        y_refiner = refine_net(y, feature)\n",
        "        score_link = y_refiner[0,:,:,0].cpu().data.numpy()\n",
        "\n",
        "    t0 = time.time() - t0\n",
        "    t1 = time.time()\n",
        "\n",
        "    # Post-processing\n",
        "    boxes, polys = getDetBoxes(score_text, score_link, text_threshold, link_threshold, low_text, poly)\n",
        "\n",
        "    # coordinate adjustment\n",
        "    boxes = adjustResultCoordinates(boxes, ratio_w, ratio_h)\n",
        "    polys = adjustResultCoordinates(polys, ratio_w, ratio_h)\n",
        "    for k in range(len(polys)):\n",
        "        if polys[k] is None: polys[k] = boxes[k]\n",
        "\n",
        "    t1 = time.time() - t1\n",
        "\n",
        "    # render results (optional)\n",
        "    render_img = score_text.copy()\n",
        "    render_img = np.hstack((render_img, score_link))\n",
        "    ret_score_text = cvt2HeatmapImg(render_img)\n",
        "\n",
        "    if args.show_time : print(\"\\ninfer/postproc time : {:.3f}/{:.3f}\".format(t0, t1))\n",
        "\n",
        "    return boxes, polys, ret_score_text\n",
        "\n",
        "\n",
        "\n",
        "# load net\n",
        "net = CRAFT()     # initialize\n",
        "\n",
        "print('Loading weights from checkpoint (' + args.trained_model + ')')\n",
        "if args.cuda:\n",
        "    net.load_state_dict(copyStateDict(torch.load(args.trained_model)))\n",
        "else:\n",
        "    net.load_state_dict(copyStateDict(torch.load(args.trained_model, map_location='cpu')))\n",
        "\n",
        "if args.cuda:\n",
        "    net = net.cuda()\n",
        "    net = torch.nn.DataParallel(net)\n",
        "    cudnn.benchmark = False\n",
        "\n",
        "net.eval()\n",
        "\n",
        "# LinkRefiner\n",
        "refine_net = None\n",
        "if args.refine:\n",
        "    refine_net = RefineNet()\n",
        "    print('Loading weights of refiner from checkpoint (' + args.refiner_model + ')')\n",
        "    if args.cuda:\n",
        "        refine_net.load_state_dict(copyStateDict(torch.load(args.refiner_model)))\n",
        "        refine_net = refine_net.cuda()\n",
        "        refine_net = torch.nn.DataParallel(refine_net)\n",
        "    else:\n",
        "        refine_net.load_state_dict(copyStateDict(torch.load(args.refiner_model, map_location='cpu')))\n",
        "\n",
        "    refine_net.eval()\n",
        "    args.poly = True\n",
        "\n",
        "t = time.time()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading weights from checkpoint (/content/gdrive/My Drive/Colab Notebooks/Dessert//weights/craft_mlt_25k.pth)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTPsL_wCVJ_v"
      },
      "source": [
        "import subprocess\n",
        "TEXT_PATH = DATA_ROOT + 'text/'\n",
        "if not os.path.isdir(TEXT_PATH):\n",
        "    os.makedirs(TEXT_PATH)\n",
        "SRC_PATH = DATA_ROOT + 'crop_dedup/'\n",
        "for src_zip in os.listdir(SRC_PATH):\n",
        "    print(src_zip)\n",
        "    os.system('rm -rf src dst src.zip dst.zip; mkdir src; mkdir dst')\n",
        "    os.system(\"cp '{}{}' src.zip\".format(SRC_PATH, src_zip))\n",
        "    name, _ = src_name = os.path.splitext(src_zip)\n",
        "    os.system('unzip -q src.zip -d src/')\n",
        "    n_imgs = len(os.listdir('src/'))\n",
        "    for i, src in enumerate(os.listdir('src/')):\n",
        "        if i%200 == 0:\n",
        "            print('{} / {}'.format(i, n_imgs))\n",
        "        image = loadImage('src/{}'.format(src))\n",
        "        bboxes, polys, score_text = test_net(net, image, 0.9, args.link_threshold, args.low_text, args.cuda, args.poly, refine_net)\n",
        "        # bboxes, polys, score_text = test_net(net, image, args.text_threshold, args.link_threshold, args.low_text, args.cuda, args.poly, refine_net)\n",
        "        if len(bboxes) > 0:\n",
        "            saveResult(src, image[:,:,::-1], polys, dirname='dst/')\n",
        "    os.system(\"cd dst; zip -q '{}.zip' ./*; mv '{}.zip' '{}'\".format(name, name, TEXT_PATH))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DR3jJTGUNJmt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}